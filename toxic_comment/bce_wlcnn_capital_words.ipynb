{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISSUES #\n",
    "## validation set에 대해 계산한 Columnwise mean ROC AUC가 실제 테스트셋에 대해 제출했을 때 값과 차이가 많이 남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- pytorch\n",
    "- torchtext\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- numpy\n",
    "- tqdm\n",
    "- gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import pandas as pd \n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 설명\n",
    "\n",
    "- embedding layer\n",
    "- |\n",
    "- convolutional layer (kernel = 3 x embedding dim)\n",
    "- |\n",
    "- leakyrelu\n",
    "- |\n",
    "- dropout\n",
    "- |\n",
    "- maxpool w.r.t time axis\n",
    "- |\n",
    "- fcn1 for each labels\n",
    "- |\n",
    "- fcn2 for each labels ( -> label output )\n",
    "- | \n",
    "- sigmoid - BinaryCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Variable(torch.randn([64,1,100,100]))\n",
    "b= Variable(torch.randn([64,1, 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 100, 100]), torch.Size([64, 1, 100]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 , 0 ,.,.) = \n",
       "  8.8214e-01  8.3378e-02 -1.9106e-01  ...   1.3042e+00  7.9262e-01  2.4372e-01\n",
       "  1.2094e+00 -1.2408e-01  1.5102e+00  ...   1.8979e-01 -1.1268e+00 -3.3760e-01\n",
       "  8.6431e-03  1.4372e+00  7.1113e-01  ...  -9.8999e-01  2.7993e+00 -2.5664e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  6.4405e-01  7.2409e-01  1.4551e+00  ...   5.4108e-02  8.2792e-01  2.2840e-01\n",
       " -6.8613e-03  1.9607e+00  1.3133e+00  ...  -6.4281e-01 -9.1896e-01 -5.8090e-01\n",
       " -1.0887e+00 -2.2818e-01  1.1619e+00  ...   7.7911e-02  2.4421e-01 -4.9161e-01\n",
       "      ⋮  \n",
       "\n",
       "( 1 , 0 ,.,.) = \n",
       "  8.1571e-01  1.2526e+00  6.0463e-01  ...   8.0458e-01  1.1654e+00  1.9355e-01\n",
       " -1.5160e+00  1.1829e+00  3.0988e-01  ...   4.2321e-01  7.5024e-01  3.8233e-01\n",
       " -1.8064e+00 -3.0960e-01  1.2396e+00  ...  -1.5141e+00 -2.5436e-01  1.5146e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  3.6366e-01 -7.6946e-01  7.5512e-02  ...  -5.0416e-01 -4.5377e-01 -1.4903e+00\n",
       " -4.1332e-01 -7.9141e-01 -3.9449e-01  ...   1.5009e+00  1.1880e-01 -1.1073e+00\n",
       " -1.2237e+00  2.0286e+00 -1.3701e+00  ...   6.0781e-01 -6.6057e-01 -1.9403e-01\n",
       "      ⋮  \n",
       "\n",
       "( 2 , 0 ,.,.) = \n",
       " -1.6198e+00  9.1447e-02  1.0316e+00  ...  -2.2365e+00  1.3870e-01 -2.3049e-01\n",
       "  3.6087e-01 -6.4161e-01  7.3145e-03  ...   9.7792e-02 -2.7344e-01 -1.2344e+00\n",
       " -6.6810e-02 -4.4273e-01  9.8725e-01  ...  -6.4714e-01 -5.1551e-02  7.1748e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.2119e+00  4.3394e-01 -2.5271e+00  ...   1.1870e+00  1.1235e+00 -3.1190e-01\n",
       " -1.8759e+00  1.2614e+00  7.4077e-01  ...  -2.8649e-01  6.6252e-01 -8.8135e-01\n",
       "  3.1929e-01 -1.4680e+00  2.5066e-01  ...   6.9721e-02 -7.9435e-03 -1.4692e+00\n",
       "...     \n",
       "      ⋮  \n",
       "\n",
       "(61 , 0 ,.,.) = \n",
       "  7.1723e-01  1.3799e+00  9.6282e-02  ...  -5.0621e-01  9.0001e-01  2.0645e-01\n",
       "  2.7099e-01  5.9799e-02 -9.1565e-01  ...  -1.4329e+00  6.9319e-01 -1.8553e-01\n",
       "  3.3569e-01  4.3072e-01  1.9061e-01  ...   6.0561e-01  1.3641e+00 -6.6220e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  3.8325e-01 -7.1340e-02 -7.0596e-01  ...   9.7097e-02  2.1180e+00  2.0288e-01\n",
       " -2.3235e-01 -1.0337e+00  7.3160e-01  ...   1.6454e-01  1.0996e+00 -1.2677e+00\n",
       "  8.7455e-01 -1.4071e+00 -1.8578e-01  ...  -1.3952e+00  1.2068e+00  4.0860e-02\n",
       "      ⋮  \n",
       "\n",
       "(62 , 0 ,.,.) = \n",
       "  6.1159e-01  2.7483e-01  6.3443e-01  ...   1.4669e+00 -3.5356e-03  1.9635e+00\n",
       " -1.6550e+00 -1.1232e+00  1.0946e+00  ...   1.0193e+00  5.4000e-01 -2.8295e-01\n",
       " -1.2428e+00  7.6066e-01  3.2843e-01  ...   1.0852e+00  5.7138e-01  5.2176e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.6252e-01 -1.5921e-01  1.4135e+00  ...  -1.8010e+00 -1.2967e+00 -4.2159e-01\n",
       "  5.0997e-01 -1.1648e+00 -1.8296e-01  ...   1.4225e-01 -9.5885e-01 -1.0748e+00\n",
       " -2.3011e-01  4.6400e-01 -1.6485e+00  ...   3.2616e-01  3.6375e-01 -3.5661e-01\n",
       "      ⋮  \n",
       "\n",
       "(63 , 0 ,.,.) = \n",
       "  1.8420e+00  7.6746e-01  6.2052e-01  ...   1.5990e+00 -1.3317e-01 -1.5107e-01\n",
       "  1.8696e-01  4.8935e-01  1.3437e+00  ...  -1.0792e+00  2.0051e+00 -4.4094e-01\n",
       " -8.6688e-01 -1.5944e+00 -6.9086e-01  ...  -8.7391e-01 -2.1598e-01  7.0818e-01\n",
       "                 ...                   ⋱                   ...                \n",
       "  8.7412e-01 -9.9253e-01  1.2609e-01  ...  -7.6329e-01 -1.2468e+00 -3.0670e-01\n",
       " -6.9242e-01  1.5305e+00  4.0853e-02  ...   5.0169e-01 -1.1959e+00  9.1168e-01\n",
       "  8.3824e-01 -7.9660e-01 -5.4768e-01  ...   1.4643e-01 -8.5112e-01 -8.0719e-01\n",
       "[torch.FloatTensor of size 64x1x100x101]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b], dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "  0.2437 -0.3376 -0.2566  ...   0.2284 -0.5809 -0.4916\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  0.1936  0.3823  1.5146  ...  -1.4903 -1.1073 -0.1940\n",
       "\n",
       "( 2 ,.,.) = \n",
       " -0.2305 -1.2344  0.7175  ...  -0.3119 -0.8814 -1.4692\n",
       "... \n",
       "\n",
       "(61 ,.,.) = \n",
       "  0.2064 -0.1855 -0.6622  ...   0.2029 -1.2677  0.0409\n",
       "\n",
       "(62 ,.,.) = \n",
       "  1.9635 -0.2829  0.5218  ...  -0.4216 -1.0748 -0.3566\n",
       "\n",
       "(63 ,.,.) = \n",
       " -0.1511 -0.4409  0.7082  ...  -0.3067  0.9117 -0.8072\n",
       "[torch.FloatTensor of size 64x1x100]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size,\n",
    "                 embedding_dim,\n",
    "                 len_sentence,\n",
    "                 channel_size=4,\n",
    "                 x2_size=1, # additional data - cap ratio\n",
    "                 fc_dim=128,\n",
    "                 padding_idx=1,\n",
    "                 dropout=0.3,\n",
    "                 num_labels=7,\n",
    "                 batch_size=32,\n",
    "                 is_cuda=False\n",
    "                ):\n",
    "        super(Net, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+2, embedding_dim=embedding_dim, padding_idx=padding_idx)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.channel_size = channel_size\n",
    "        self.len_sentence = len_sentence\n",
    "        self.batch_size = batch_size\n",
    "        self.x2_size = x2_size\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(1, out_channels=channel_size, kernel_size=(5, embedding_dim + 1), stride=1)\n",
    "        # output : batch x channel x (len_sentence - 2) x 1\n",
    "        \n",
    "        # -> squeeze : batch x channel x (len_sentence - 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout1d = nn.Dropout(p=dropout)\n",
    "        self.pool1d = nn.AvgPool1d(kernel_size=2)\n",
    "        # output : batch x channel x (len_sentence - 2) / 2\n",
    "        \n",
    "        self.bottleneck_size = channel_size * (len_sentence - 4) / 2\n",
    "        assert self.bottleneck_size.is_integer()\n",
    "        self.bottleneck_size = int(self.bottleneck_size) + self.x2_size\n",
    "        \n",
    "        self.fcn1 = nn.Linear(self.bottleneck_size, fc_dim)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.fcn2 = nn.Linear(fc_dim, num_labels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc_dim = fc_dim\n",
    "        self.num_labels = num_labels\n",
    "    \n",
    "    def forward(self, sentence, cap_ratio, other_features):\n",
    "#         print(\"sentence \", sentence.shape)\n",
    "        image = self.embedding(sentence)\n",
    "#         print(bottleneck.shape)\n",
    "#         image.unsqueeze_(1)\n",
    "#         print(\"image \", image.shape)\n",
    "        # batch x channel x sentence_length x embedding\n",
    "        cap_ratio.unsqueeze_(2)\n",
    "#         print(\"cap_Ratio :\", cap_ratio.shape)\n",
    "        new_image = torch.cat([image, cap_ratio], dim=2)\n",
    "        new_image.unsqueeze_(1)\n",
    "        bottleneck = self.conv2d(new_image)\n",
    "        bottleneck.squeeze_(3)\n",
    "        bottleneck = self.relu(bottleneck) # batch x channel x features\n",
    "        bottleneck = self.dropout1d(bottleneck)\n",
    "        bottleneck = self.pool1d(bottleneck)\n",
    "#         print(\"bt shape \", bottleneck.shape)\n",
    "        \n",
    "        bottleneck = bottleneck.view(-1, self.bottleneck_size - self.x2_size)\n",
    "        if self.x2_size > 0:\n",
    "            bottleneck = torch.cat([bottleneck, other_features], dim=1)\n",
    "        \n",
    "        fcn = self.relu1(self.fcn1(bottleneck))\n",
    "        fcn = self.fcn2(fcn)\n",
    "        logit = self.sigmoid(fcn)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    vocab_size = 20000\n",
    "    embedding_dim = 100 # TODO: max 300\n",
    "    len_sentence = 100\n",
    "    num_labels = 6\n",
    "    min_freq = 1\n",
    "    batch_size = 64\n",
    "    channel_size = 128\n",
    "    seed = 0\n",
    "    dropout = 0.5 # TODO: batch norm으로 대체 추천\n",
    "    x2_size = 0\n",
    "    valid_num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# seed 고정\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pd_data(path : str):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = get_pd_data('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = get_pd_data('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess (1)\n",
    "----\n",
    "###  Set captial character ratio\n",
    "- 문장 내의 대문자 비율을 뉴럴넷의 input으로 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_capital_ratio(df : pd.DataFrame):\n",
    "    df['alphas'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isalpha()))\n",
    "    df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "    df['cap_ratio'] = df.apply(lambda row: float(row['capitals']) / (float(row['alphas']) + 1), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_capital_ratio(train), set_capital_ratio(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>alphas</th>\n",
       "      <th>capitals</th>\n",
       "      <th>cap_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>17</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>11</td>\n",
       "      <td>0.022587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  alphas  capitals  \\\n",
       "0             0        0       0       0              0     203        17   \n",
       "1             0        0       0       0              0      73         8   \n",
       "2             0        0       0       0              0     186         4   \n",
       "3             0        0       0       0              0     486        11   \n",
       "4             0        0       0       0              0      50         2   \n",
       "\n",
       "   cap_ratio  \n",
       "0   0.083333  \n",
       "1   0.108108  \n",
       "2   0.021390  \n",
       "3   0.022587  \n",
       "4   0.039216  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess(2)\n",
    "-----\n",
    "### Word tokenize\n",
    "- gensim의 tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweetcocoa\\Anaconda3\\envs\\torch\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(string : str):\n",
    "    return [s for s in simple_tokenize(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cap_ratio_of_words(tokens : list):\n",
    "    return [(sum(1 for c in token if c.isupper()))/(sum(1 for c in token if c.isalpha()) + 1) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_train = train['comment_text'].apply(tokenizer)\n",
    "tk_test = train['comment_text'].apply(tokenizer)\n",
    "tk_cap_ratio_train = tk_train.apply(get_cap_ratio_of_words)\n",
    "tk_cap_ratio_test = tk_test.apply(get_cap_ratio_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk_train = train['comment_text'].str.lower().apply(tokenizer)\n",
    "tk_test = train['comment_text'].str.lower().apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.08333333333333333, 0.25, 0.0, 0.0, 0.0, 0.0...\n",
       "1    [0.5, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, ...\n",
       "2    [0.25, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "3    [0.2, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4    [0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_cap_ratio_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [explanation, why, the, edits, made, under, my...\n",
       "1    [d, aww, he, matches, this, background, colour...\n",
       "2    [hey, man, i, m, really, not, trying, to, edit...\n",
       "3    [more, i, can, t, make, any, real, suggestions...\n",
       "4    [you, sir, are, my, hero, any, chance, you, re...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "x_features = ['cap_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess(3)\n",
    "----\n",
    "### Add Normal column label\n",
    "- toxic하지 않은 label로 분류되는 것에, normal=1 의 새로운 라벨 추가 (하지않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['normal'] = 0\n",
    "# train.loc[train[labels].sum(axis=1) == 0, 'normal'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels.append('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0\n",
       "5      0             0        0       0       0              0\n",
       "6      1             1        1       0       1              0\n",
       "7      0             0        0       0       0              0\n",
       "8      0             0        0       0       0              0\n",
       "9      0             0        0       0       0              0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = train[labels]\n",
    "y_labels.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap_ratio\n",
       "0   0.083333\n",
       "1   0.108108\n",
       "2   0.021390\n",
       "3   0.022587\n",
       "4   0.039216\n",
       "5   0.021277\n",
       "6   0.973684\n",
       "7   0.043478\n",
       "8   0.019391\n",
       "9   0.033333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add manually engineered features ex) capital ratio of sentence\n",
    "x2 = train[x_features]\n",
    "x2.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "----\n",
    "### 10000 개의 Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x, y, z : pd.Dataframe of pd.series\n",
    "def shuffle_lists(*pargs):\n",
    "    shuffler = np.random.permutation(len(pargs[0]))\n",
    "    retargs = []\n",
    "    for x in pargs:\n",
    "        x = x.iloc[shuffler]\n",
    "        retargs.append(x)\n",
    "    return retargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding_cap_ratio(tokens : list):\n",
    "    L = len(tokens)\n",
    "    ret = tokens[:min(L, config.len_sentence)]\n",
    "    ret = [0] * (config.len_sentence - L) + ret\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk_train, x2, tk_cap_ratio_train, y_labels = shuffle_lists(tk_train, x2, tk_cap_ratio_train, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_cap_ratio_train = np.array([padding_cap_ratio(row) for row in tk_cap_ratio_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk_valid = tk_train[-config.valid_num:]\n",
    "tk_cap_ratio_valid = tk_cap_ratio_train[-config.valid_num:]\n",
    "x2_valid = x2[-config.valid_num:]\n",
    "y_valid = y_labels[-config.valid_num:]\n",
    "\n",
    "tk_train = tk_train[:-config.valid_num]\n",
    "y_train = y_labels[:-config.valid_num]\n",
    "x2_train = x2[:-config.valid_num]\n",
    "tk_cap_ratio_train = tk_cap_ratio_train[:-config.valid_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000, 10000, 10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk_valid), len(tk_cap_ratio_valid), len(x2_valid), len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149571, 149571, 149571, 149571)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk_train), len(tk_cap_ratio_train), len(x2_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess(3)\n",
    "---\n",
    "### torchtext.data.Field\n",
    "- word dictionary, word to index 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,  \n",
    "                  # 들어갈 데이터가 sequential 인가요? 우리는 tokenize한 word의 sequence를 다룰거니까 True입니다. Defualt로도 True임.\n",
    "                  tokenize=tokenizer, \n",
    "                  # 그 데이터를 tokenize할 함수를 지정할 수 있습니다. 우리는 gensim library의 tokenize 함수를 쓸건데요\n",
    "                  # 뭐 굳이 그거 말고도 직접 정의해도 되고 str.split 같은걸 써넣어도 됩니다.\n",
    "                  # :: 그런 줄 알았는데 아무 tokenize 함수나 쓰면 안되고, generator가 아닌 tokenized list 를 반환하는 함수여야합니다..\n",
    "                  # :::: 이게 아닐거같기도 함.\n",
    "                  fix_length=config.len_sentence,\n",
    "                 # 아마 tokenize된 길이 제한 같은데 한번 확인해볼게요. 특이사항으로는 length 넘으면 자르고, 안넘으면 padding을 채웁니다\n",
    "                  # :: 그게 아니고 vector화 했을 때의 길이 제한일 것 같아요. 확인해보겠습니다.\n",
    "                  pad_first=True,\n",
    "                  # padding이 앞에서부터 붙냐, 뒤에서부터 붙냐는 겁니다.\n",
    "                  tensor_type=torch.cuda.LongTensor\n",
    "                  # cuda를 써도 됩니다\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(tk_train, tk_valid, max_size=config.vocab_size, min_freq=config.min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchify(*pargs, batch_size=32):\n",
    "    for i in range(0, len(pargs[0]), batch_size):\n",
    "        end = min(i+batch_size, len(tk_train))\n",
    "        yield [batch[i:end] for batch in pargs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net(vocab_size=config.vocab_size, embedding_dim=config.embedding_dim, len_sentence=config.len_sentence,\n",
    "         x2_size=config.x2_size, channel_size=config.channel_size, dropout=config.dropout, num_labels=config.num_labels, batch_size=config.batch_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(20002, 100, padding_idx=1)\n",
       "  (conv2d): Conv2d (1, 128, kernel_size=(5, 101), stride=(1, 1))\n",
       "  (relu): ReLU(inplace)\n",
       "  (dropout1d): Dropout(p=0.5)\n",
       "  (pool1d): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,), ceil_mode=False, count_include_pad=True)\n",
       "  (fcn1): Linear(in_features=6144, out_features=128)\n",
       "  (relu1): ReLU(inplace)\n",
       "  (fcn2): Linear(in_features=128, out_features=6)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "# criterions = [nn.CrossEntropyLoss() for i in range(config.num_labels)]\n",
    "# -> Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation(net, tk_valid, tk_cap_ratio_valid, x2_valid, y_valid : pd.DataFrame, TEXT : data.Field, criterion):\n",
    "    net.train(False)\n",
    "    val_score = None\n",
    "    valid_loss = 0 \n",
    "    for val_step, (batch_val, cr_val, x2_val, y_val) in enumerate(batchify(tk_valid, tk_cap_ratio_valid, x2_valid.values, y_valid.values, batch_size=config.batch_size)):\n",
    "        var_x = TEXT.process(batch_val, device=0, train=False).transpose(dim0=0, dim1=1)\n",
    "        var_cr = Variable(torch.cuda.FloatTensor(cr_val))\n",
    "        var_y = Variable(torch.cuda.FloatTensor(y_val))\n",
    "        var_x2 = Variable(torch.cuda.FloatTensor(x2_val))\n",
    "        pred_score = net(var_x, var_cr, var_x2)\n",
    "        if val_score is None:\n",
    "            val_score = pred_score\n",
    "        else:\n",
    "            val_score = torch.cat([val_score, pred_score])\n",
    "        y_loss = criterion(pred_score, var_y)\n",
    "        valid_loss += y_loss.data[0]\n",
    "    net.train(True)\n",
    "    valid_loss /= len(tk_valid) / config.batch_size\n",
    "            \n",
    "    return valid_loss, val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "996it [00:09, 102.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss 0.05752939092963934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1997it [00:20, 99.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss 0.05879605170637369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2338it [00:24, 96.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_corrects = [0 for i in range(config.num_labels)]\n",
    "train_loss = 0\n",
    "net.train(True)\n",
    "for step, (x_train_, cr_train_, x2_train_, y_train_) in tqdm(enumerate(batchify(tk_train, tk_cap_ratio_train, x2_train.values, y_train.values, batch_size=config.batch_size))):\n",
    "    var_x = TEXT.process(x_train_, device=0, train=True).transpose(dim0=0, dim1=1)\n",
    "    var_cr = Variable(torch.cuda.FloatTensor(cr_train_))\n",
    "    var_y = Variable(torch.cuda.FloatTensor(y_train_))\n",
    "    var_x2 = Variable(torch.cuda.FloatTensor(x2_train_))\n",
    "    pred_score = net(var_x, var_cr, var_x2)\n",
    "    \n",
    "    net.zero_grad()\n",
    "    \n",
    "    \n",
    "    y_loss = criterion(pred_score, var_y)\n",
    "#     if step % 100 == 99:\n",
    "#         print(y_loss.data[0])\n",
    "    y_loss.backward()\n",
    "    if step % 1000 == 999:\n",
    "        valid_loss, val_score = validation(net, tk_valid, tk_cap_ratio_valid, x2_valid, y_valid, TEXT, criterion)\n",
    "        print(\"valid loss\", valid_loss)\n",
    "#         print(\"valid acc\", [i.data[0] for i in valid_acc])\n",
    "\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_loss, val_score = validation(net, tk_valid, tk_cap_ratio_valid, x2_valid, y_valid, TEXT, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "---\n",
    "### roc_auc_score w.r.t. validation set's score\n",
    "- Kaggle form에 맞추어 column-wise roc auc score 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965691001184\n",
      "0.985493937663\n",
      "0.981482735949\n",
      "0.973019586525\n",
      "0.975710950977\n",
      "0.957344804756\n"
     ]
    }
   ],
   "source": [
    "roc_auc_scores = 0\n",
    "for i in range(config.num_labels): # minus 1 for normal \n",
    "    score = roc_auc_score( y_valid[labels[i]].values, val_score.data.cpu().numpy()[:, i])\n",
    "    print(score)\n",
    "    roc_auc_scores += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973123836176\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_scores / (config.num_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 0.975129977385 - CHANNEL 128 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.5 + AvgPool1d between CNN + sentence length 100 + embedding 100 + min_freq 1 + kernel size 5 + epoch 3\n",
    "- 0.971308288115 - same above + word capital embedding + epoch 2\n",
    "- 0.973348269027 - same above + epoch 3\n",
    "- 0.973123836176 - same above + epoch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
