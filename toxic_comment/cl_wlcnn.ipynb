{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISSUES #\n",
    "## validation set에 대해 계산한 Columnwise mean ROC AUC가 실제 테스트셋에 대해 제출했을 때 값과 차이가 많이 남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- pytorch\n",
    "- torchtext\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- numpy\n",
    "- tqdm\n",
    "- gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import pandas as pd \n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 설명\n",
    "\n",
    "- embedding layer\n",
    "- |\n",
    "- convolutional layer (kernel = 3 x embedding dim)\n",
    "- |\n",
    "- leakyrelu\n",
    "- |\n",
    "- dropout\n",
    "- |\n",
    "- maxpool w.r.t time axis\n",
    "- |\n",
    "- fcn1 for each labels\n",
    "- | | | | | | |\n",
    "- fcn2 for each labels ( -> binary output )\n",
    "- | | | | | | |\n",
    "- CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size,\n",
    "                 embedding_dim,\n",
    "                 len_sentence,\n",
    "                 channel_size=4,\n",
    "                 x2_size=1, # additional data - cap ratio\n",
    "                 fc_dim=128,\n",
    "                 padding_idx=1,\n",
    "                 dropout=0.3,\n",
    "                 num_labels=7,\n",
    "                 batch_size=32,\n",
    "                 is_cuda=False\n",
    "                ):\n",
    "        super(Net, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+2, embedding_dim=embedding_dim, padding_idx=padding_idx)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.channel_size = channel_size\n",
    "        self.len_sentence = len_sentence\n",
    "        self.batch_size = batch_size\n",
    "        self.x2_size = x2_size\n",
    "        \n",
    "        self.conv2d = nn.Conv2d(1, out_channels=channel_size, kernel_size=(5, embedding_dim), stride=1)\n",
    "        # output : batch x channel x (len_sentence - 2) x 1\n",
    "        \n",
    "        # -> squeeze : batch x channel x (len_sentence - 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout1d = nn.Dropout(p=dropout)\n",
    "        self.pool1d = nn.AvgPool1d(kernel_size=2)\n",
    "        # output : batch x channel x (len_sentence - 2) / 2\n",
    "        \n",
    "        self.bottleneck_size = channel_size * (len_sentence - 4) / 2\n",
    "#         print (\"Linear size : %sx(%s-2)/2\"%(channel_size, len_sentence), self.bottleneck_size)\n",
    "        assert self.bottleneck_size.is_integer()\n",
    "        self.bottleneck_size = int(self.bottleneck_size) + self.x2_size\n",
    "        \n",
    "        self.fcns1 = [nn.Linear(self.bottleneck_size, fc_dim) for i in range(num_labels)]\n",
    "        self.relu1 = [nn.ReLU(inplace=True) for i in range(num_labels)]\n",
    "        self.fcns2 = [nn.Linear(fc_dim, 2) for i in range(num_labels)]\n",
    "        \n",
    "        \n",
    "        for i in range(num_labels):\n",
    "            self.add_module(\"fcn1-\"+str(i), self.fcns1[i])\n",
    "        for i in range(num_labels):\n",
    "            self.add_module(\"relu1-\"+str(i), self.relu1[i])\n",
    "        for i in range(num_labels):\n",
    "            self.add_module(\"fcn2-\"+str(i), self.fcns2[i])\n",
    "        \n",
    "        self.fc_dim = fc_dim\n",
    "        self.num_labels = num_labels\n",
    "    \n",
    "    def forward(self, sentence, other_features):\n",
    "#         print(\"sentence \", sentence.shape)\n",
    "        image = self.embedding(sentence)\n",
    "#         print(bottleneck.shape)\n",
    "        image.unsqueeze_(1)\n",
    "#         print(\"image \", image.shape)\n",
    "        \n",
    "        bottleneck = self.conv2d(image)\n",
    "        bottleneck.squeeze_(3)\n",
    "        bottleneck = self.relu(bottleneck) # batch x channel x features\n",
    "        bottleneck = self.dropout1d(bottleneck)\n",
    "        bottleneck = self.pool1d(bottleneck)\n",
    "#         print(\"bt shape \", bottleneck.shape)\n",
    "        \n",
    "        bottleneck = bottleneck.view(-1, self.bottleneck_size - self.x2_size)\n",
    "        if self.x2_size > 0:\n",
    "            bottleneck = torch.cat([bottleneck, other_features], dim=1)\n",
    "\n",
    "        fcns_1 = []\n",
    "        for i in range(self.num_labels):\n",
    "            fcns_1.append(self.relu1[i](self.fcns1[i](bottleneck)))\n",
    "        \n",
    "        fcns_2 = []\n",
    "        for i in range(self.num_labels):\n",
    "            fcns_2.append(self.fcns2[i](fcns_1[i]))\n",
    "            \n",
    "        return fcns_2 # return num_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    vocab_size = 20000\n",
    "    embedding_dim = 100 # TODO: max 300\n",
    "    len_sentence = 100\n",
    "    num_labels = 7 # TODO: 6 강추\n",
    "    min_freq = 1\n",
    "    batch_size = 64\n",
    "    channel_size = 128\n",
    "    seed = 0\n",
    "    dropout = 0.5 # TODO: batch norm으로 대체 추천\n",
    "    x2_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# seed 고정\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pd_data(path : str):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = get_pd_data('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = get_pd_data('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess (1)\n",
    "----\n",
    "###  Set captial character ratio\n",
    "- 문장 내의 대문자 비율을 뉴럴넷의 input으로 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_capital_ratio(df : pd.DataFrame):\n",
    "    df['alphas'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isalpha()))\n",
    "    df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "    df['cap_ratio'] = df.apply(lambda row: float(row['capitals']) / (float(row['alphas']) + 1), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_capital_ratio(train), set_capital_ratio(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>alphas</th>\n",
       "      <th>capitals</th>\n",
       "      <th>cap_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>17</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>11</td>\n",
       "      <td>0.022587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  alphas  capitals  \\\n",
       "0             0        0       0       0              0     203        17   \n",
       "1             0        0       0       0              0      73         8   \n",
       "2             0        0       0       0              0     186         4   \n",
       "3             0        0       0       0              0     486        11   \n",
       "4             0        0       0       0              0      50         2   \n",
       "\n",
       "   cap_ratio  \n",
       "0   0.083333  \n",
       "1   0.108108  \n",
       "2   0.021390  \n",
       "3   0.022587  \n",
       "4   0.039216  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess(2)\n",
    "-----\n",
    "### Word tokenize\n",
    "- gensim의 tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(string : str):\n",
    "    return [s for s in simple_tokenize(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk_train = train['comment_text'].str.lower().apply(tokenizer)\n",
    "tk_test = train['comment_text'].str.lower().apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [explanation, why, the, edits, made, under, my...\n",
       "1    [d, aww, he, matches, this, background, colour...\n",
       "2    [hey, man, i, m, really, not, trying, to, edit...\n",
       "3    [more, i, can, t, make, any, real, suggestions...\n",
       "4    [you, sir, are, my, hero, any, chance, you, re...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "x_features = ['cap_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess(3)\n",
    "----\n",
    "### Add Normal column label\n",
    "- toxic하지 않은 label로 분류되는 것에, normal=1 의 새로운 라벨 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['normal'] = 0\n",
    "train.loc[train[labels].sum(axis=1) == 0, 'normal'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels.append('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  normal\n",
       "0      0             0        0       0       0              0       1\n",
       "1      0             0        0       0       0              0       1\n",
       "2      0             0        0       0       0              0       1\n",
       "3      0             0        0       0       0              0       1\n",
       "4      0             0        0       0       0              0       1\n",
       "5      0             0        0       0       0              0       1\n",
       "6      1             1        1       0       1              0       0\n",
       "7      0             0        0       0       0              0       1\n",
       "8      0             0        0       0       0              0       1\n",
       "9      0             0        0       0       0              0       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = train[labels]\n",
    "y_labels.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap_ratio\n",
       "0   0.083333\n",
       "1   0.108108\n",
       "2   0.021390\n",
       "3   0.022587\n",
       "4   0.039216\n",
       "5   0.021277\n",
       "6   0.973684\n",
       "7   0.043478\n",
       "8   0.019391\n",
       "9   0.033333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add manually engineered features ex) capital ratio of sentence\n",
    "x2 = train[x_features]\n",
    "x2.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "----\n",
    "### 10000 개의 Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x, y, z : pd.Dataframe of pd.series\n",
    "def shuffle_x_y(x , x2, y):\n",
    "    shuffler = np.random.permutation(len(x))\n",
    "    x = x.iloc[shuffler]\n",
    "    y = y.iloc[shuffler]\n",
    "    x2 = x2.iloc[shuffler]\n",
    "    return x, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk_train, x2, y_labels = shuffle_x_y(tk_train, x2, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk_valid = tk_train[-valid_num:]\n",
    "y_valid = y_labels[-valid_num:]\n",
    "tk_train = tk_train[:-valid_num]\n",
    "y_labels = y_labels[:-valid_num]\n",
    "x2_valid = x2[-valid_num:]\n",
    "x2_train = x2[:-valid_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess(3)\n",
    "---\n",
    "### torchtext.data.Field\n",
    "- word dictionary, word to index 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,  \n",
    "                  # 들어갈 데이터가 sequential 인가요? 우리는 tokenize한 word의 sequence를 다룰거니까 True입니다. Defualt로도 True임.\n",
    "                  tokenize=tokenizer, \n",
    "                  # 그 데이터를 tokenize할 함수를 지정할 수 있습니다. 우리는 gensim library의 tokenize 함수를 쓸건데요\n",
    "                  # 뭐 굳이 그거 말고도 직접 정의해도 되고 str.split 같은걸 써넣어도 됩니다.\n",
    "                  # :: 그런 줄 알았는데 아무 tokenize 함수나 쓰면 안되고, generator가 아닌 tokenized list 를 반환하는 함수여야합니다..\n",
    "                  # :::: 이게 아닐거같기도 함.\n",
    "                  fix_length=config.len_sentence,\n",
    "                 # 아마 tokenize된 길이 제한 같은데 한번 확인해볼게요. 특이사항으로는 length 넘으면 자르고, 안넘으면 padding을 채웁니다\n",
    "                  # :: 그게 아니고 vector화 했을 때의 길이 제한일 것 같아요. 확인해보겠습니다.\n",
    "                  pad_first=True,\n",
    "                  # padding이 앞에서부터 붙냐, 뒤에서부터 붙냐는 겁니다.\n",
    "                  tensor_type=torch.cuda.LongTensor\n",
    "                  # cuda를 써도 됩니다\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(tk_train, tk_valid, max_size=config.vocab_size, min_freq=config.min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchify(tk_train, x2, y_labels, batch_size=32):\n",
    "    for i in range(0, len(tk_train), batch_size):\n",
    "        end = min(i+batch_size, len(tk_train))\n",
    "        yield tk_train[i:end], x2[i:end], y_labels[i:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net(vocab_size=config.vocab_size, embedding_dim=config.embedding_dim, len_sentence=config.len_sentence,\n",
    "         x2_size=config.x2_size, channel_size=config.channel_size, dropout=config.dropout, num_labels=config.num_labels, batch_size=config.batch_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(20002, 100, padding_idx=1)\n",
       "  (conv2d): Conv2d (1, 128, kernel_size=(5, 100), stride=(1, 1))\n",
       "  (relu): ReLU(inplace)\n",
       "  (dropout1d): Dropout(p=0.5)\n",
       "  (pool1d): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,), ceil_mode=False, count_include_pad=True)\n",
       "  (fcn1-0): Linear(in_features=6145, out_features=128)\n",
       "  (fcn1-1): Linear(in_features=6145, out_features=128)\n",
       "  (fcn1-2): Linear(in_features=6145, out_features=128)\n",
       "  (fcn1-3): Linear(in_features=6145, out_features=128)\n",
       "  (fcn1-4): Linear(in_features=6145, out_features=128)\n",
       "  (fcn1-5): Linear(in_features=6145, out_features=128)\n",
       "  (fcn1-6): Linear(in_features=6145, out_features=128)\n",
       "  (relu1-0): ReLU(inplace)\n",
       "  (relu1-1): ReLU(inplace)\n",
       "  (relu1-2): ReLU(inplace)\n",
       "  (relu1-3): ReLU(inplace)\n",
       "  (relu1-4): ReLU(inplace)\n",
       "  (relu1-5): ReLU(inplace)\n",
       "  (relu1-6): ReLU(inplace)\n",
       "  (fcn2-0): Linear(in_features=128, out_features=2)\n",
       "  (fcn2-1): Linear(in_features=128, out_features=2)\n",
       "  (fcn2-2): Linear(in_features=128, out_features=2)\n",
       "  (fcn2-3): Linear(in_features=128, out_features=2)\n",
       "  (fcn2-4): Linear(in_features=128, out_features=2)\n",
       "  (fcn2-5): Linear(in_features=128, out_features=2)\n",
       "  (fcn2-6): Linear(in_features=128, out_features=2)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters())\n",
    "criterions = [nn.CrossEntropyLoss() for i in range(config.num_labels)]\n",
    "# -> Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation(net, tk_valid, x2_valid, y_valid : pd.DataFrame, TEXT : data.Field, criterions : list):\n",
    "    net.train(False)\n",
    "    val_corrects = [0 for i in range(config.num_labels)]\n",
    "    val_score = []\n",
    "    valid_loss = 0 \n",
    "    sigmoid = nn.Sigmoid()\n",
    "    for val_step, (batch_val, x2_val, y_val) in enumerate(batchify(tk_valid, x2_valid.values, y_valid.values, batch_size=config.batch_size)):\n",
    "        y_total_loss = 0\n",
    "        var_batch = TEXT.process(batch_val, device=0, train=False).transpose(dim0=0, dim1=1)\n",
    "        var_y = Variable(torch.cuda.LongTensor(y_val)).transpose(dim0=0, dim1=1)\n",
    "        var_x2 = Variable(torch.cuda.FloatTensor(x2_val))\n",
    "        pred_score = net(var_batch, var_x2)\n",
    "        val_score.append([sigmoid(score).data.cpu() for score in pred_score])\n",
    "        for i, score in enumerate(pred_score):\n",
    "            _, pred = score.max(dim=1)\n",
    "            val_corrects[i] += (pred == var_y[i]).float().sum()\n",
    "            y_loss = criterions[i](score, var_y[i])\n",
    "            y_total_loss += y_loss\n",
    "        valid_loss += y_total_loss\n",
    "    net.train(True)\n",
    "    valid_loss /= len(tk_valid) / config.batch_size\n",
    "    \n",
    "    for i, val_correct in enumerate(val_corrects):\n",
    "        val_corrects[i] = val_corrects[i] / len(tk_valid)\n",
    "        \n",
    "    return valid_loss, val_corrects, val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1012it [00:10, 94.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss Variable containing:\n",
      " 0.4560\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "valid acc [0.9587999582290649, 0.9889999628067017, 0.9767999649047852, 0.9968999624252319, 0.9693999886512756, 0.9908999800682068, 0.9577999711036682]\n",
      "y_total_loss 0.552423894405365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2013it [00:21, 94.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss Variable containing:\n",
      " 0.4402\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "valid acc [0.9607999920845032, 0.9891999959945679, 0.9763000011444092, 0.9968999624252319, 0.9674999713897705, 0.9908999800682068, 0.9606999754905701]\n",
      "y_total_loss 0.796908974647522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2338it [00:24, 95.65it/s]\n"
     ]
    }
   ],
   "source": [
    "train_corrects = [0 for i in range(config.num_labels)]\n",
    "train_loss = 0\n",
    "net.train(True)\n",
    "for step, (batch, x2, y_label) in tqdm(enumerate(batchify(tk_train, x2_train.values, y_labels.values, batch_size=config.batch_size))):\n",
    "    var_batch = TEXT.process(batch, device=0, train=True).transpose(dim0=0, dim1=1)\n",
    "    var_y = Variable(torch.cuda.LongTensor(y_label)).transpose(dim0=0, dim1=1)\n",
    "    var_x2 = Variable(torch.cuda.FloatTensor(x2))\n",
    "    pred_score = net(var_batch, var_x2)\n",
    "    \n",
    "    net.zero_grad()\n",
    "    y_total_loss = 0\n",
    "    for i, score in enumerate(pred_score):\n",
    "        _, pred = score.max(dim=1)\n",
    "        train_corrects[i] += (pred == var_y[i]).float().sum()\n",
    "        y_loss = criterions[i](score, var_y[i])\n",
    "#         print(y_loss.data[0])\n",
    "        y_total_loss += y_loss\n",
    "    \n",
    "    \n",
    "    if step % 1000 == 999:\n",
    "        valid_loss, valid_acc, val_score = validation(net, tk_valid, x2_valid, y_valid, TEXT, criterions)\n",
    "        print(\"valid loss\", valid_loss)\n",
    "        print(\"valid acc\", [i.data[0] for i in valid_acc])\n",
    "        print(\"y_total_loss\", y_total_loss.data[0])\n",
    "    y_total_loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_loss, valid_acc, val_score = validation(net, tk_valid, x2_valid, y_valid, TEXT, criterions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [] # 모든 라벨의 validation set에 대한 예측값\n",
    "for i in range(config.num_labels):\n",
    "    prediction = [s[i] for s in val_score] # i번째 라벨에 대한 예측값을 배치에 따라 모음\n",
    "    predictions.append(torch.cat(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "---\n",
    "### roc_auc_score w.r.t. validation set's score\n",
    "- Kaggle form에 맞추어 column-wise roc auc score 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965643741112\n",
      "0.983693775685\n",
      "0.97803789524\n",
      "0.964748785752\n",
      "0.974100205935\n",
      "0.946592009262\n"
     ]
    }
   ],
   "source": [
    "roc_auc_scores = 0\n",
    "for i in range(config.num_labels - 1): # minus 1 for normal \n",
    "    score = roc_auc_score( y_valid[labels[i]].values, predictions[i].numpy()[:, 1])\n",
    "    print(score)\n",
    "    roc_auc_scores += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968802735498\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_scores / (config.num_labels - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 0.928248892508\n",
    "- 0.928127157466\n",
    "- 0.935732919807 - CHANNEL 24\n",
    "- 0.934171154598 - CHANNEL 64\n",
    "- 0.948519433931 - CHANNEL 64 + PURE RELU between FCN\n",
    "- 0.949684088036 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN\n",
    "- 0.949644094585 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.5\n",
    "- 0.950924024766 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.5 + AvgPool1d between CNN\n",
    "- 0.949550358684 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.3 + AvgPool1d between CNN\n",
    "- 0.960614877434 - same + 2epoch\n",
    "- 0.960766345684 - same + 3epoch\n",
    "- 0.950225198889 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.3 + AvgPool1d between CNN + capital ratio\n",
    "- 0.960447066963 - same + 2epoch\n",
    "- 0.962149265317 - same + 3epoch\n",
    "- 0.954162859988 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.3 + AvgPool1d between CNN + capital ratio + sentence length 50\n",
    "- 0.962025767267 - same + 2epoch\n",
    "- 0.965634499276 - same + 3epoch\n",
    "- 0.964100160935 - same + 4epoch (score down)\n",
    "- 0.962314010080 - same + 5epoch (score down)\n",
    "- 0.959030453926 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.3 + AvgPool1d between CNN + capital ratio + sentence length 50 + embedding 100\n",
    "- 0.964376057907 - same + 2epoch\n",
    "- 0.964409415850 - same + 3epoch\n",
    "- 0.963119039023 - same + 4epoch (score down)\n",
    "- 0.959078240257 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.3 + AvgPool1d between CNN + capital ratio + sentence length 50 + embedding 100 + min_freq 1\n",
    "- 0.963425059656 - same + 2epoch\n",
    "- 0.964142162405 - same + 3epoch\n",
    "- 0.958696961492 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.3 + AvgPool1d between CNN + capital ratio + sentence length 50 + embedding 100 + min_freq 1\n",
    "- 0.965250520502 - same + 2epoch\n",
    "- 0.964957852521 - same + 3epoch (score down)\n",
    "- 0.959665545778 - CHANNEL 64 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.3 + AvgPool1d between CNN + sentence length 50 + embedding 100 + min_freq 1\n",
    "- 0.964868120935 - same + 2epoch\n",
    "- 0.965769582949 - same + 3epoch\n",
    "- 0.966142587757 - same + 4epoch\n",
    "- 0.963965925012 - same + 5epoch\n",
    "- 0.968513983110 - CHANNEL 128 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.5 + AvgPool1d between CNN + sentence length 100 + embedding 100 + min_freq 1\n",
    "- 0.970571357335 - same + 2epoch\n",
    "- 0.971408464827 - same + 3epoch\n",
    "- 0.969902034731 - same + 4epoch (score down)\n",
    "- 0.966766524384 - CHANNEL 128 + PURE RELU between FCN + PURE RELU between CNN + dropout 0.5 + AvgPool1d between CNN + sentence length 100 + embedding 100 + min_freq 1 + kernel size 5\n",
    "- 0.971493644385 - same + 2epoch\n",
    "- 0.970291057843 - same + 3epoch (score down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_recsys]",
   "language": "python",
   "name": "conda-env-tf_recsys-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
